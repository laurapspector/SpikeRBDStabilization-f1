import itertools as it
import os
import configparser
import numpy as np
import pandas as pd
import scipy.stats
import scipy.optimize
from statsmodels.stats.rates import test_poisson_2indep

from matplotlib import pyplot as plt

from analysis.aa_nt_dist import min_nt_dist
from analysis.heatmap import write_heatmap
from dms.dna import *
from dms.arguments import *

def variant_min_nt_dist(variant):
    """Return the minimum number of nucleotide changes to get from one
    amino acid to another.

    variant: A string describing a mutation, e.g. 'A102W'.
    """
    return min_nt_dist(variant[0], variant[-1])

def pois_exact_test(row, ratio_null=1):
    """Hypothesis test on the ratio of two Poisson rate parameters.

    The null hypothese is that the ratio of the selected population
    rate to the reference population rate is <= ratio_null.

    row: object with fields sel_counts, sel_total, ref_counts, and
         ref_total.

    Returns a p-value.
    """
    p = test_poisson_2indep(row.sel_counts, row.sel_total,
                            row.ref_counts, row.ref_total,
                            value=ratio_null,  # "ratio_null" is deprecated in favor of "value"
                            alternative='larger',
                            method='exact-cond')
    return p.pvalue

def calculate_ER_threshold(d, fdr, size):
    """Given a control experiment, compute an ER threshold that should
    correspond to a given FDR.

    d: DataFrame with column 'ER'.
    fdr: Target false detection rate.
    size: Number of variants in the experiment.

    Returns an ER threshold.
    """
    er_range = 10 # A big number definitely larger than the ER of interest.
    p = fdr / size
    kde = scipy.stats.gaussian_kde(d['ER'])
    thresh = scipy.optimize.root_scalar(
        lambda x: kde.integrate_box_1d(-np.inf, x) - (1-p),
        bracket=[-er_range, er_range]).root
    # Sanity check that the integration worked.
    assert abs((1-p) - kde.integrate_box_1d(-np.inf, thresh)) < 1e-10
    return thresh

def make_FDR_calculator(d, size):
    """Given a control experiment, return a function that will compute the
    FDR for a given ER.

    d: DataFrame with column 'ER'.
    size: Number of variants in the experiment.

    Returns a function.
    """
    kde = scipy.stats.gaussian_kde(d['ER'])
    def calculate_FDR(ER, size=size, kde=kde):
        return size * (1 - kde.integrate_box_1d(-np.inf, ER))
    return calculate_FDR

def read_table(path):
    """Read a CSV file generated by the dms code."""
    d = pd.read_csv(path)
    d[['tile', 'name']] = d['experiment'].str.split('_', expand=True)
    d['tile'] = d['tile'].astype(int)
    d['name'] = 'CC.' + d['name']
    return d[['name', 'tile', 'variant', 'sel_counts',
              'sel_total', 'ref_counts', 'ref_total', 'ER']]

def maybe_quoted_string(s):
    if len(s) > 0 and s[0] in ["'", '"']:
        return ast.literal_eval(s)
    else:
        return s

def parse_args_again(args):
    positions = {}
    wt_seq = {}

    params, tiles, samples, experiments, proteins = parse_args_and_read_config(args)

    for k in tiles.keys():
        t_seq = translate_sequence(tiles[k].wt_seq[tiles[k].cds_start:tiles[k].cds_end])
        positions[int(k[1:])] = [x for x in tiles[k].positions]
        for num in range(0, len(t_seq)):
            wt_seq[num + int(tiles[k].first_aa)] = t_seq[num]

    return positions, wt_seq, params.output_dir

def parse_analysis(c):
    if not c.has_section('Analysis'):
        raise argparse.ArgumentTypeError('config does not have a [Analysis]'
                                         ' section.')

    for name, value in c.items('Analysis'):
        if name == 'control_filepath': c = maybe_quoted_string(value)
        if name == 'antibody_filepath': a = maybe_quoted_string(value)
        if name == 'FDR': f = float(value)
        if name == 'significance': s = float(value)
        if name == 'output_title': o = maybe_quoted_string(value)

    return c, a, f, s, o

def perform_analysis(c_file, a_file, fdr, significance, out, sizes, prd, all_positions, wt_seq):
    Abs = ['nAb']
    tiles = [1, 2, 3, 4, 5, 6, 7, 8]
    replicates = [1]

    control = \
        {(rep, tile) : group
         for (rep, d) in [(rep, read_table(c_file))
                          for rep in replicates]
         for (tile, group) in d.groupby('tile')}

    data = \
        {(Ab, rep, tile) : group
         for ((Ab, rep), d) in [((Ab, rep),
                                 read_table(a_file))
                                for (Ab, rep) in it.product(Abs, replicates)
                                if os.path.exists(a_file)]
         for (tile, group) in d.groupby('tile')}

    thresholds = {(rep, tile) : calculate_ER_threshold(d, fdr, sizes[tile])
                  for ((rep, tile), d) in control.items()}

    FDR_calcs = {(rep, tile) : make_FDR_calculator(d, sizes[tile])
                 for ((rep, tile), d) in control.items()}


    for (Ab, rep, tile), d in data.items():
        d['min_nt_dist'] = d['variant'].apply(variant_min_nt_dist)
        ER_thresh = thresholds[rep, tile]
        d['ER_thresh'] = ER_thresh
        ratio = 2**ER_thresh
        d['pval'] = d.apply(pois_exact_test, axis=1, ratio_null=ratio)
        d['FDR'] = d['ER'].apply(FDR_calcs[rep, tile])


    for Ab, rep in it.product(Abs, replicates):
        dfs = [data[Ab, rep, tile]
               for tile in tiles
               if (Ab, rep, tile) in data]
        if len(dfs) == 0: continue
        d = pd.concat(dfs)
        if not os.path.exists(os.path.join(prd, 'Processed')):
            os.makedirs(os.path.join(prd, 'Processed'))
        d.to_csv(os.path.join(prd, 'Processed', f'{out}.csv'), index=False)
        write_heatmap(os.path.join(prd, 'Processed', f'{out}_heatmap.xlsx'),
                      wt_seq, all_positions, [d], 'ER', significance)

def main(argv):
    if not os.path.exists('Processed'):
        os.makedirs('Processed')

    if argv[0] != '--config':
        print('--config was not given as the first command line argument')
        quit()

    current_directory = os.getcwd()
    processed_directory = os.path.join(current_directory, 'Processed')

    positions, wt_seq, processed_directory = parse_args_again(argv)  # I have edited this to allow path configuration
    all_positions = sorted(it.chain(*positions.values()))

    # Library sizes for each tile. The libraries are NNKs that target all
    # 20 mutations (19 AA mutations and a stop) at each position.
    sizes = {tile : 20 * len(pos) for (tile, pos) in positions.items()}

    config = configparser.ConfigParser(strict=True)
    config.optionxform = str # make the parser case-sensitive
    config.read(argv[1])
    c_file, a_file, fdr, significance, out = parse_analysis(config)

    perform_analysis(c_file, a_file, fdr, significance, out, sizes, processed_directory, all_positions, wt_seq)

    return
